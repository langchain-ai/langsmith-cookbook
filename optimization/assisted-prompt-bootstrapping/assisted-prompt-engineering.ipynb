{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56f6b50-d708-43c5-acd2-ad948cdc1797",
   "metadata": {},
   "source": [
    "# Prompt Bootstrapping with LangSmith + Claude\n",
    "\n",
    "Prompt engineering can be frustrating, especially when it comes to tasks where metrics are hard to defined. Crafting a prompt is often an iterative process, refining it over multiple examples.\n",
    "\n",
    "Turns out LLMs can do a [decent job at prompt engineering](https://arxiv.org/abs/2211.01910), especially when incorporating human feedback on representative data. \n",
    "\n",
    "In this notebook, we will walk through \"prompt bootstrapping\", where you will iteratively refine a prompt by providing unstructured feedback over a dataset. Below is an overview of the process.\n",
    "\n",
    "![Prompt Bootstrapping Diagram](./img/prompt-bootstrapping.png)\n",
    "\n",
    "LangSmith makes this this whole flow very easy. Let's give it a whirl!\n",
    "\n",
    "This example is based on [@alexalbert's example Claude workflow](https://x.com/alexalbert__/status/1767258557039378511?s=20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191baa94-41b2-4aaf-b621-aaf8171566d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langsmith langchain_anthropic langchain arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b20f9596-dcd5-4928-a6f0-e4f75e1cf843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Update with your API URL if using a hosted instance of Langsmith.\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"YOUR API KEY\"  # Update with your API key\n",
    "# We are using Anthropic here as well\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR API KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5ac85d1-d72f-482e-8488-6a848ae98c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "prompt_name = \"YOUR HUB REPO HERE\"  # Example: wfh/tweet-generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fb8d0a-7618-4d93-ae82-ae150a3acc28",
   "metadata": {},
   "source": [
    "# 1. Pick a task\n",
    "\n",
    "Let's say I want to write a tweet generator about academic papers, one that is catchy but not laden with too many buzzwords\n",
    "or impersonal. Let's see if we can \"optimize\" a prompt without having to engineer it ourselves.\n",
    "\n",
    "We will use the meta-prompt ([wfh/metaprompt](https://smith.langchain.com/hub/wfh/metaprompt)) from the Hub to generate our first prompt candidate to solve this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90d087d0-4a76-4046-82d7-dddf8361bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "task = (\n",
    "    \"Generate a tweet to market an academic paper or open source project. It should be\"\n",
    "    \" well crafted but avoid gimicks or over-reliance on buzzwords.\"\n",
    ")\n",
    "\n",
    "\n",
    "# See: https://smith.langchain.com/hub/wfh/metaprompt\n",
    "prompt = hub.pull(\"wfh/metaprompt\")\n",
    "llm = ChatAnthropic(model=\"claude-3-opus-20240229\")\n",
    "\n",
    "\n",
    "def get_instructions(gen: str):\n",
    "    return gen.split(\"<Instructions>\")[1].split(\"</Instructions>\")[0]\n",
    "\n",
    "\n",
    "meta_prompter = prompt | llm | StrOutputParser() | get_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6e6a7b-f3f7-4fe6-87f5-7e78340a8489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/hub/wfh/academic-tweet-generator/034c6661'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "recommended_prompt_str = meta_prompter.invoke(\n",
    "    {\n",
    "        # This is the high level purpose of the system\n",
    "        \"task\": task,\n",
    "        # These are the values your system will accept\n",
    "        \"input_variables\": \"\"\"\n",
    "{paper}\n",
    "\"\"\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# We'll commit each version of our prompt to the Hub\n",
    "# so you can track or revisit each iteration.\n",
    "recommended_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"user\", recommended_prompt_str)]\n",
    ")\n",
    "hub.push(prompt_name, recommended_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac4c64-98f8-43e4-ad63-a7797a9b6396",
   "metadata": {},
   "source": [
    "OK so it's a fine-not-great prompt. Let's see how it does!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64f33f-328b-4609-b248-fa52214b5b76",
   "metadata": {},
   "source": [
    "## 2. Dataset\n",
    "\n",
    "For some tasks you can generate them yourselves. For our notebook, we have created a 10-datapoint dataset of some scraped ArXiv papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e9ef2ef-d7be-4f41-b947-73407319611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
    "\n",
    "wrapper = ArxivAPIWrapper(doc_content_chars_max=200_000)\n",
    "docs = list(islice(wrapper.lazy_load(\"Self-Replicating Language model Agents\"), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "088a1625-d8ad-4760-91c9-db7073476ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Languages¬†for¬†Mobile¬†Agents \n",
      "Steven¬†Versteeg¬†\n",
      "¬†\n",
      "Supervisor:¬†Leon¬†Sterling¬†\n",
      "¬†\n",
      "433¬≠463¬†Thesis¬†\n",
      "Department¬†of¬†Computer¬†Science¬†and¬†Software¬†Engineering¬†\n",
      "University¬†of¬†Melbourne¬†\n",
      "¬†25¬†August,¬†1997¬†\n",
      "¬†‚ÄãAbstract¬†\n",
      "Mobile¬†agents¬†represent¬†a¬†new¬†model¬†for¬†network¬†computing.¬†¬†Many¬†different¬†languages¬†\n",
      "have¬†be\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc80f9da-db1f-41c9-8db1-0f92b3acb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = \"Tweet Generator\"\n",
    "ds = client.create_dataset(dataset_name=ds_name)\n",
    "client.create_examples(\n",
    "    inputs=[{\"paper\": doc.page_content} for doc in docs], dataset_id=ds.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dda2b0-e4f7-4394-9b65-6f4316399392",
   "metadata": {},
   "source": [
    "## 3. Predict\n",
    "\n",
    "We will refrain from defining metrics for now (it's quite subjective). Instead we will run the first version of the generator against the dataset and manually review + provide feedback on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54cd01c1-8859-4fe7-a8ed-1ef430c475a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What makes a programming language suitable for writing mobile agents? Key factors:\n",
      "- Migration support\n",
      "- Agent communication \n",
      "- Interfaces to server resources\n",
      "- Security\n",
      "- Efficiency & portability\n",
      "Java, Telescript, Agent Tcl & others compared in this '97 paper\n",
      "http://www.cs.mu.oz.au/~scv/433-463/thesis_only.pdf\n",
      "#MobileAgents #ProgrammingLanguages\n"
     ]
    }
   ],
   "source": [
    "def parse_tweet(response: str):\n",
    "    try:\n",
    "        return response.split(\"<tweet>\")[1].split(\"</tweet>\")[0].strip()\n",
    "    except:\n",
    "        return response.strip()\n",
    "\n",
    "\n",
    "def create_tweet_generator(prompt):\n",
    "    return prompt | llm | StrOutputParser() | parse_tweet\n",
    "\n",
    "\n",
    "tweet_generator = create_tweet_generator(recommended_prompt)\n",
    "\n",
    "# Example\n",
    "prediction = tweet_generator.invoke({\"paper\": docs[0].page_content})\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a87a9b2d-a2fe-4e55-bc50-6e7bef4f98ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'sunny-stem-33' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/0433274f-e08b-43a1-9fea-018375080012/compare?selectedSessions=dfaa7ab6-b211-4e56-a6d2-caed9a10f68a\n",
      "\n",
      "View all tests for Dataset Tweet Generator at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/0433274f-e08b-43a1-9fea-018375080012\n",
      "[------------------------------------------------->] 5/5"
     ]
    }
   ],
   "source": [
    "res = client.run_on_dataset(\n",
    "    dataset_name=ds_name,\n",
    "    llm_or_chain_factory=tweet_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9a554-7504-4070-9a2a-ed0c09e656fc",
   "metadata": {},
   "source": [
    "## 4. Label\n",
    "\n",
    "Now, we will use an annotation queue to score + add notes to the results. We will use this to iterate on our prompt!\n",
    "\n",
    "For this notebook, I will be logging two types of feedback:\n",
    "\n",
    "`note`- freeform comments on the runs\n",
    "\n",
    "`tweet_quality` - a 0-4 score of the generated tweet based on my subjective preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94a24156-a2a9-49ee-98e9-f2f3d8f9ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = client.create_annotation_queue(name=\"Tweet Generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b6c2406-eb48-4abb-99f0-b8993ce607d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_runs_to_annotation_queue(\n",
    "    q.id,\n",
    "    run_ids=[\n",
    "        r.id\n",
    "        for r in client.list_runs(project_name=res[\"project_name\"], execution_order=1)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae068c97-ced9-4496-b7a5-57213e493325",
   "metadata": {},
   "source": [
    "Now, go through the runs to label them. Return to this notebook when you are finished.\n",
    "\n",
    "![Queue](./img/queue.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ed075-38de-4a09-b073-63807039550e",
   "metadata": {},
   "source": [
    "## 4. Update\n",
    "\n",
    "With the human feedback in place, let's update the prompt and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75f8f65e-40af-4c40-8ca4-ca07831b28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def format_feedback(single_feedback, max_score=4):\n",
    "    if single_feedback.score is None:\n",
    "        score = \"\"\n",
    "    else:\n",
    "        score = f\"\\nScore:[{single_feedback.score}/{max_score}]\"\n",
    "    comment = f\"\\n{single_feedback.comment}\".strip()\n",
    "    return f\"\"\"<feedback key={single_feedback.key}>{score}{comment}\n",
    "</feedback>\"\"\"\n",
    "\n",
    "\n",
    "def format_run_with_feedback(run, feedback):\n",
    "    all_feedback = \"\\n\".join([format_feedback(f) for f in feedback])\n",
    "    return f\"\"\"<example>\n",
    "<tweet>\n",
    "{run.outputs[\"output\"]}\n",
    "</tweet>\n",
    "<annotations>\n",
    "{all_feedback}\n",
    "</annotations>\n",
    "</example>\"\"\"\n",
    "\n",
    "\n",
    "def get_formatted_feedback(project_name: str):\n",
    "    traces = list(client.list_runs(project_name=project_name, execution_order=1))\n",
    "    feedbacks = defaultdict(list)\n",
    "    for f in client.list_feedback(run_ids=[r.id for r in traces]):\n",
    "        feedbacks[f.run_id].append(f)\n",
    "    return [\n",
    "        format_run_with_feedback(r, feedbacks[r.id])\n",
    "        for r in traces\n",
    "        if r.id in feedbacks\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fd4c807-ef3f-4520-a77f-ad813252f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_feedback = get_formatted_feedback(res[\"project_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c907a-73d3-45c5-812f-9631bb63c21c",
   "metadata": {},
   "source": [
    "LLMs are especially good at 2 things:\n",
    "1. Generating grammatical text\n",
    "2. Summarization\n",
    "\n",
    "Now that we've left a mixture of scores and free-form comments, we can use an \"optimizer prompt\" ([wfh/optimizerprompt](https://smith.langchain.com/hub/wfh/optimizerprompt)) to incorporate the feedback into an updated prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b41aa18b-a99e-4927-a155-83b8cdb4c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://smith.langchain.com/hub/wfh/optimizerprompt\n",
    "optimizer_prompt = hub.pull(\"wfh/optimizerprompt\")\n",
    "\n",
    "\n",
    "def extract_new_prompt(gen: str):\n",
    "    return gen.split(\"<improved_prompt>\")[1].split(\"</improved_prompt>\")[0].strip()\n",
    "\n",
    "\n",
    "optimizer = optimizer_prompt | llm | StrOutputParser() | extract_new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8f42771-a135-44c9-9534-e6f572089d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/hub/wfh/academic-tweet-generator/4c8cbfd0'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_prompt_str = recommended_prompt_str\n",
    "new_prompt_str = optimizer.invoke(\n",
    "    {\n",
    "        \"current_prompt\": current_prompt_str,\n",
    "        \"annotated_predictions\": \"\\n\\n\".join(formatted_feedback).strip(),\n",
    "    }\n",
    ")\n",
    "# Check in a new version of the prompt to the Hub\n",
    "new_prompt = ChatPromptTemplate.from_messages([(\"user\", new_prompt_str)])\n",
    "hub.push(prompt_name, new_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eac1918-1c85-420a-9519-a924a11a8f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prompt\n",
      "\n",
      "\n",
      "\n",
      "{paper}\n",
      "\n",
      "Please carefully read the above paper (or excerpt). Identify the key contributions, insights, or results that would be most interesting to a general technical audience on Twitter.\n",
      "\n",
      "Draft an engaging, concise tweet summarizing the key interesting points of the paper for a general audience. Do not sensationalize or over-hype the claims - be accurate. But do try to pique the reader's curiosity to learn more. Please include a link to the full paper at the end of the tweet.\n",
      "\n",
      "Write your draft tweet here:\n",
      "\n",
      "<tweet>\n",
      "\n",
      "</tweet>\n",
      "\n",
      "Now please review your draft tweet. Edit it to:\n",
      "- Remove/replace technical jargon where possible \n",
      "- Add 1-2 relevant hashtags\n",
      "- @mention any relevant Twitter accounts (e.g. authors, institutions, etc) if you can identify them\n",
      "- Check that the key claims are accurately conveyed\n",
      "- Trim the tweet to fit within Twitter's character limit if needed\n",
      "\n",
      "Here is the final, refined tweet:\n",
      "\n",
      "<tweet>\n",
      "\n",
      "</tweet>\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "New Prompt\n",
      "\n",
      "Please read the paper or excerpt below and identify the key contributions, insights or results that would be most interesting to share with a general audience on Twitter. \n",
      "\n",
      "{paper}\n",
      "\n",
      "Draft a tweet summarizing the paper's key points for a general audience. The tweet should meet the following criteria:\n",
      "\n",
      "- Accurately conveys the central claims and significance of the research \n",
      "- Describes the work in an engaging way to capture interest\n",
      "- Explains key concepts in plain, accessible language (minimize jargon)\n",
      "- Is concise and focused (1-2 key points max)\n",
      "\n",
      "Here is an example of an effective tweet summary:\n",
      "\n",
      "\"New research from MIT reveals how AI can be used to detect early signs of Alzheimer's from speech patterns - with over 90% accuracy. This non-invasive approach could enable earlier diagnosis and treatment. https://...\"\n",
      "\n",
      "This is effective because it clearly describes the key research finding and significance in plain language, while also being engaging and including a relevant link.\n",
      "\n",
      "Draft your tweet here:\n",
      "\n",
      "<tweet1>\n",
      "\n",
      "</tweet1>\n",
      "\n",
      "Now please critically reflect on your draft. Check how well it meets the criteria above. Identify any technical jargon that could be rephrased in simpler language. Look for opportunities to make the phrasing more engaging or capture interest. But above all, ensure the central claims are accurately conveyed.\n",
      "\n",
      "Revise your tweet here:\n",
      "\n",
      "<tweet2>\n",
      "\n",
      "</tweet2>\n",
      "\n",
      "Finally, polish your tweet to:\n",
      "- Include 1-2 relevant hashtags\n",
      "- @mention relevant accounts like authors or institutions if identifiable \n",
      "- Ensure it fits within Twitter's character limit\n",
      "\n",
      "Share the final polished tweet here:\n",
      "\n",
      "<tweet3>\n",
      "\n",
      "</tweet3>\n",
      "\n",
      "The key changes are:\n",
      "\n",
      "- Providing a clearer rubric for an effective tweet summary\n",
      "- Including an example of a high-quality summary\n",
      "- Prompting more critical reflection and targeted revision\n",
      "- Splitting initial drafting and later polishing into distinct steps\n",
      "- Prioritizing accuracy above all else\n",
      "\n",
      "I believe these changes will help guide the AI to produce tweet summaries that are first and foremost accurate, while also being clear, engaging and well-targeted to a general audience. The added structure and examples should help boost scores across the key criteria.\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Prompt\\n\\n\" + current_prompt_str)\n",
    "print(\"*\" * 80 + \"\\nNew Prompt\\n\\n\" + new_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "041831a8-9f5c-4e36-863c-3f0a4aeb25d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Languages for mobile agents: What features do they need? ü§ñüó∫Ô∏è\\n- Built-in support for agent migration, communication, security \\n- Cross-platform execution on heterogeneous networks\\n- Balance of performance & ease of programming\\n\\nEnabling software agents to roam the internet autonomously, interacting with servers along the way!\\n\\nhttp://www.cs.mu.oz.au/~sversteeg/research/thesis.html'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with the new prompt\n",
    "tweet_generator = create_tweet_generator(new_prompt)\n",
    "tweet_generator.invoke({\"paper\": docs[0].page_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316756d0-30d9-45bd-a3f4-e737bf4430de",
   "metadata": {},
   "source": [
    "## 5. Repeat!\n",
    "\n",
    "Now that we have an \"upgraded\" prompt, we can test it out again and repeat until we are satisfied with the result.\n",
    "\n",
    "If you find the prompt isn't converging to something you want, you can manually update the prompt (you are the optimizer in this case) and/or be more explicit in your free-form note feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2aef764-ef56-4e21-83ac-f51f7f0e7112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'ample-club-93' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/0433274f-e08b-43a1-9fea-018375080012/compare?selectedSessions=65b80c98-e8e4-45f5-a11b-d7fe41fb98c8\n",
      "\n",
      "View all tests for Dataset Tweet Generator at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/0433274f-e08b-43a1-9fea-018375080012\n",
      "[------------------------------------------------->] 5/5"
     ]
    }
   ],
   "source": [
    "updated_results = client.run_on_dataset(\n",
    "    dataset_name=ds_name,\n",
    "    llm_or_chain_factory=tweet_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58ac7137-a6c1-4c5a-aacb-cc1bd66b0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_runs_to_annotation_queue(\n",
    "    q.id,\n",
    "    run_ids=[\n",
    "        r.id\n",
    "        for r in client.list_runs(\n",
    "            project_name=updated_results[\"project_name\"], execution_order=1\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ed160-28d4-493e-8e10-6420ded71e1a",
   "metadata": {},
   "source": [
    "**Next, review again** and provide feedback. Optionally repeat.\n",
    "\n",
    "Once you've provided feedback, you can continue here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f403a5f8-00b2-4d20-8d3b-b5f1cf050718",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_feedback = get_formatted_feedback(updated_results[\"project_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5103da25-8b28-44dc-b816-a972cff3c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap them out\n",
    "current_prompt_str = new_prompt_str\n",
    "new_prompt_str = optimizer.invoke(\n",
    "    {\n",
    "        \"current_prompt\": current_prompt_str,\n",
    "        \"annotated_predictions\": \"\\n\\n\".join(formatted_feedback).strip(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5e46e96-ad32-4251-8e51-72d9bf582a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Prompt\n",
      "\n",
      "Please carefully read the paper (or excerpt) below and identify the key contributions, insights, or results that would be most interesting and valuable to share with a general technical audience on Twitter:\n",
      "\n",
      "{paper}\n",
      "\n",
      "Your goal is to write an informative and engaging long-form tweet (500-750 characters) that accurately conveys the paper's main ideas, key details and results, and significance. \n",
      "\n",
      "The tweet should follow this structure:\n",
      "\n",
      "1. Key message: Start with an attention-grabbing title or key takeaway that draws the reader in and makes them want to learn more. Keep it concise yet compelling.\n",
      "\n",
      "2. Main body: Provide specific details about the methods, results, novelty or implications that a broad audience would find most interesting and valuable. Include data, numbers, key findings, hypotheses tested, etc. Give enough information that the reader gets substantial insight into the work without needing to read the full paper. Use clear language but don't oversimplify.\n",
      "\n",
      "3. Significance: Explain briefly why the research matters and how it might impact the field or the world. What's the potential real-world value?\n",
      "\n",
      "4. Hashtags, mentions and link: Include 1-2 relevant hashtags, @mention any author or institution Twitter handles, and link to the full paper.\n",
      "\n",
      "Prioritize accurately representing the paper's actual claims and contributions. Avoid exaggerating or mischaracterizing the work for the sake of engagement. Fascinate the reader with the genuine insights and implications.\n",
      "\n",
      "Here's an example of an excellent long-form tweet:\n",
      "\n",
      "\"Want to control a robot with your brain? ü§ñüß† New study from @MIT_CSAIL paves the way! \n",
      "\n",
      "By analyzing EEG data with deep learning, their system can detect brain signals to move a robotic arm in real-time with 97% accuracy - even tracking minute finger movements. üëÜ\n",
      "\n",
      "This \"mind-reading\" approach translates neural activity into fine-grained robotic control faster and more precisely than ever before. Potential applications include:\n",
      "\n",
      "- Assistive tech for paralyzed individuals\n",
      "- Intuitive control for complex robots\n",
      "- Brain-machine interface research \n",
      "\n",
      "Could this be a key step toward sci-fi dreams like mind-controlled exoskeletons? The authors believe it lays important groundwork for melding human and machine intelligence. ü¶æüîÆ\n",
      "\n",
      "Lots more work ahead to make it practical and accessible, but an exciting glimpse of the future! Check out the details: https://nature.com/articles/s415467-023-1234-9\n",
      "\n",
      "#BrainComputerInterface #Robotics #AI #Neuroscience #HumanAugmentation\"\n",
      "\n",
      "Now it's your turn! Draft the best long-form tweet you can, following the guidelines above:\n",
      "\n",
      "<tweet>\n",
      "\n",
      "</tweet>\n",
      "********************************************************************************\n",
      "New Prompt\n",
      "\n",
      "Please carefully read the paper (or excerpt) below and identify the key contributions, insights, or results that would be most interesting and valuable to share with a general technical audience on Twitter:\n",
      "\n",
      "{paper}  \n",
      "\n",
      "Your goal is to write an informative and engaging long-form tweet (minimum 500-750 characters) that accurately conveys the paper's main ideas, key details and results, and significance to a broad audience. \n",
      "\n",
      "The tweet should follow this clear structure:\n",
      "\n",
      "1. Key message: Start with an attention-grabbing title or key takeaway that draws the reader in and makes them want to learn more. Keep it concise yet compelling.\n",
      "\n",
      "2. Main body: Provide specific details about the methods, results, novelty or implications that a general audience would find most interesting and valuable. Include data, numbers, key findings, hypotheses tested, etc. Give enough information that the reader gets substantial insight into the work without needing to read the full paper. Use clear language but don't oversimplify. Explain any jargon.\n",
      "\n",
      "3. Significance: Explain briefly why the research matters and how it might impact the field or the world. What's the potential real-world value?\n",
      "\n",
      "4. Hashtags, mentions and link: Include 1-2 relevant hashtags, @mention any author or institution Twitter handles, and link to the full paper.\n",
      "\n",
      "Prioritize accurately representing the paper's actual claims and contributions. Avoid exaggerating or mischaracterizing the work for the sake of engagement. Fascinate the reader with the genuine insights and implications.\n",
      "\n",
      "Here's an example of an excellent long-form tweet:\n",
      "\n",
      "\"Want to control a robot with your brain? ü§ñüß† New study from @MIT_CSAIL paves the way! \n",
      "\n",
      "By analyzing EEG data with deep learning, their system can detect brain signals to move a robotic arm in real-time with 97% accuracy - even tracking minute finger movements. üëÜ\n",
      "\n",
      "This \"mind-reading\" approach translates neural activity into fine-grained robotic control faster and more precisely than ever before. Potential applications include:\n",
      "\n",
      "- Assistive tech for paralyzed individuals \n",
      "- Intuitive control for complex robots\n",
      "- Brain-machine interface research\n",
      "\n",
      "Could this be a key step toward sci-fi dreams like mind-controlled exoskeletons? The authors believe it lays important groundwork for melding human and machine intelligence. ü¶æüîÆ\n",
      "\n",
      "Lots more work ahead to make it practical and accessible, but an exciting glimpse of the future! Check out the details: https://nature.com/articles/s415467-023-1234-9\n",
      "\n",
      "#BrainComputerInterface #Robotics #AI #Neuroscience #HumanAugmentation\"\n",
      "\n",
      "Now it's your turn! Draft the best long-form tweet you can, following the guidelines above. Remember, aim for 500-750 characters minimum, packed with interesting specifics. Get the reader excited about the work and its potential impact!\n",
      "\n",
      "<tweet>\n",
      "\n",
      "</tweet>\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous Prompt\\n\\n\" + current_prompt_str)\n",
    "print(\"*\" * 80 + \"\\nNew Prompt\\n\\n\" + new_prompt_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b952f0d-a3e2-4e09-99eb-af75c03416f2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congrats! You've \"optimized\" a prompt on a subjective task using human feedback and an automatic prompt engineer flow. LangSmith makes it easy to score and improve LLM systems even when it is hard to craft a hard metric.\n",
    "\n",
    "You can push the optimized version of your prompt to the hub (here and in future iterations) to version each change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "817d82e4-98b4-4902-9f29-05df7a21621d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/hub/wfh/academic-tweet-generator/5bfbea74'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prompt = ChatPromptTemplate.from_messages([(\"user\", new_prompt_str)])\n",
    "hub.push(prompt_name, new_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dda2af7f-14c1-44e9-a832-b0c42f6f76c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What makes a programming language well-suited for developing mobile agents? ü§î This 1997 thesis examines the essential characteristics:\n",
      "\n",
      "Key requirements include support for agent migration, inter-agent communication, interfacing with host resources, security mechanisms, execution efficiency, cross-platform availability, and ease of programming. üìã\n",
      "\n",
      "The paper compares languages like Telescript, Java, Agent Tcl and Obliq. Telescript was designed specifically for mobile agents and elegantly handles migration, communication and security. ‚úÖ \n",
      "\n",
      "But Java, despite being general-purpose, provides the core capabilities and holds the advantage of being an open standard supported across many platforms. ‚òï\n",
      "\n",
      "The work anticipates a future where mobile agents roam the internet to search for information, monitor data, engage in e-commerce and distribute computation. Though 25+ years old, it identifies issues still relevant as multi-agent systems become prevalent. üîÆ\n",
      "\n",
      "While many competing languages existed, the author presciently saw that only a few widely-supported ones would enable the mobile agent vision to become a mainstream reality. üèÜ\n",
      "\n",
      "Full thesis available here: https://example.com/thesis.pdf\n",
      "\n",
      "#MobileAgents #MultiAgentSystems #ProgrammingLanguages #DistributedComputing #InternetComputing\n"
     ]
    }
   ],
   "source": [
    "tweet_generator = create_tweet_generator(new_prompt)\n",
    "result = tweet_generator.invoke({\"paper\": docs[0].page_content})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22adabff-26ff-48ec-8faf-d0d43031f2c0",
   "metadata": {},
   "source": [
    "#### Extensions:\n",
    "\n",
    "We haven't optimized the meta-prompts above - feel free to make them your own by forking and updating them!\n",
    "Some easy extensions you could try out include:\n",
    "1. Including the full history of previous prompts and annotations (or most recent N prompts with feedback) in the \"optimizer prompt\" step. This may help it better converge (especially if you're using a small dataset)\n",
    "2. Updating the optimizer prompt to encourage usage of few-shot examples, or to encourage other prompting tricks.\n",
    "3. Incorporating an LLM judge by including the annotation few-shot examples and instructing it to critique the generated outputs: this could help speed-up the human annotation process.\n",
    "4. Generating and including a validation set (to avoid over-fitting this training dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e4b74c-c977-4310-876c-a5ecf4f2e635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
