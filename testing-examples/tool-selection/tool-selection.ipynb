{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6344e99-4dd7-4898-9a9d-516a1076ed54",
   "metadata": {},
   "source": [
    "## Tool Selection Evaluation\n",
    "\n",
    "Tool selection refers to the ability of an LLM to select the appropriate tools from a list in order to respond to a user query.\n",
    "\n",
    "This notebook walks through how to measure the selected tool precision, including a follow step to try to automatically update the tool descriptions to address errors present in the first pass.\n",
    "\n",
    "We will use a subset of the [ToolBench](https://github.com/OpenBMB/ToolBench/tree/master) dataset in these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865947b4-9ce1-4a76-96bc-76a656abe8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5062b-91e5-4a8e-9d46-4ebfa53ec280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Update with your API URL if using a hosted instance of Langsmith.\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"YOUR API KEY\"  # Update with your API key\n",
    "# Optional: \"default\" is used if not set\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Tool Selection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1a4652-11dd-4c9c-b882-05def42115ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset_url = (\n",
    "    \"https://smith.langchain.com/public/bdf7611c-3420-4c71-a492-42715a32d61e/d\"\n",
    ")\n",
    "dataset_name = \"Tool Selection (Logistics) dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f951dbc-01d9-4482-a51f-095ce0660f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langsmith\n",
    "\n",
    "client = langsmith.Client()\n",
    "\n",
    "client.clone_public_dataset(dev_dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff0ea7-0f9c-4f6c-aeae-d9361dae5e8f",
   "metadata": {},
   "source": [
    "## Define Metrics\n",
    "\n",
    "\n",
    "We will compute the intersection over union metric of the tools selected for the first logical step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a18b5b77-9000-4eb1-8b34-d4aa84708479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "\n",
    "from langchain.smith import RunEvalConfig\n",
    "from langsmith.evaluation import run_evaluator\n",
    "\n",
    "\n",
    "@run_evaluator\n",
    "def selected_tools_precision(run, example):\n",
    "    expected = example.outputs[\"expected\"]\n",
    "    predicted = run.outputs[\"output\"]\n",
    "    expected: Set[str] = {tool for tools in expected for tool in tools}\n",
    "    predicted: Set[str] = {tool[\"type\"] for tool in predicted}\n",
    "    true_positives = predicted & expected\n",
    "\n",
    "    if len(predicted) == 0:\n",
    "        if len(expected) > 0:\n",
    "            score = 0\n",
    "        else:\n",
    "            score = 1\n",
    "    else:\n",
    "        score = len(true_positives) / len(predicted)\n",
    "    return {\"key\": \"tool_selection_precision\", \"score\": score}\n",
    "\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    custom_evaluators=[selected_tools_precision],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc664e2-d88d-444c-9bc5-4b60a9d105dc",
   "metadata": {},
   "source": [
    "## Create model\n",
    "\n",
    "We will perform simple function calling using the tools appropriate for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce123ef5-c8fe-4522-84e7-2790ce8e8e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'TransportistasdeArgentina',\n",
       "  'description': 'Quote for postcode in OCA e-Pack.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'postCodeDst': {'type': 'number',\n",
       "     'description': 'Postcode Destination'},\n",
       "    'cuit': {'type': 'string',\n",
       "     'description': 'CUIT of your account in OCA e-Pack'},\n",
       "    'operativa': {'type': 'string',\n",
       "     'description': 'Operativa number of your account in OCA e-Pack'},\n",
       "    'cost': {'type': 'number', 'description': 'Cost of products in ARS'},\n",
       "    'postCodeSrc': {'type': 'number', 'description': 'Postcode Source'},\n",
       "    'volume': {'type': 'number', 'description': 'Volume in cm3'},\n",
       "    'weight': {'type': 'number', 'description': 'Weight in KG'}},\n",
       "   'required': ['postCodeDst',\n",
       "    'cuit',\n",
       "    'operativa',\n",
       "    'cost',\n",
       "    'postCodeSrc',\n",
       "    'volume',\n",
       "    'weight']}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./data/tools.json\") as f:\n",
    "    tools = json.load(f)\n",
    "\n",
    "# Example tool\n",
    "tools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58935649-8aa6-47ea-a64d-84122e6f6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Respond to the user's query using the provided tools\",\n",
    "        ),\n",
    "        (\"user\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=model).bind_tools(tools)\n",
    "\n",
    "chain = assistant_prompt | llm | JsonOutputToolsParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa4c04-5b0f-4126-9d83-aad3de2740fd",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75d194a4-0cd1-4b34-836f-ef4b5c405a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'clear-jet-37' at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/462d8386-60c8-4cb3-84eb-6efeae3a1293/compare?selectedSessions=8b95a94e-c05f-4ecf-b749-aeaef3ff3327\n",
      "\n",
      "View all tests for Dataset Tool Selection (Logistics) dev at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/462d8386-60c8-4cb3-84eb-6efeae3a1293\n",
      "[------------------------------------------------->] 100/100"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.tool_selection_precision</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>827e2f98-bcb1-4940-aa16-5a7d0eca80ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.636667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.417737</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.370322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.581734</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.468482</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.141958</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.331713</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576078</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.320643</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.tool_selection_precision error  execution_time  \\\n",
       "count                          100.000000     0      100.000000   \n",
       "unique                                NaN     0             NaN   \n",
       "top                                   NaN   NaN             NaN   \n",
       "freq                                  NaN   NaN             NaN   \n",
       "mean                             0.636667   NaN        1.417737   \n",
       "std                              0.370322   NaN        0.581734   \n",
       "min                              0.000000   NaN        0.468482   \n",
       "25%                              0.333333   NaN        1.141958   \n",
       "50%                              0.500000   NaN        1.331713   \n",
       "75%                              1.000000   NaN        1.576078   \n",
       "max                              1.000000   NaN        4.320643   \n",
       "\n",
       "                                      run_id  \n",
       "count                                    100  \n",
       "unique                                   100  \n",
       "top     827e2f98-bcb1-4940-aa16-5a7d0eca80ff  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results = client.run_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=eval_config,\n",
    "    verbose=True,\n",
    "    project_metadata={\n",
    "        \"model\": model,\n",
    "        \"tool_variant\": 0,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0064eb29-dd91-4d63-a540-dd8f6c616ddd",
   "metadata": {},
   "source": [
    "After evaluating, we'd recommend reviewing the results and manually identifying issues you can fix. This is a noisy dataset that we haven't yet cleaned, so you will likely want to fix the labels to actually serve as the ground truth.\n",
    "\n",
    "If you want to try something more automated (but less reliable), read on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642e586-8e6a-4fd6-bd2e-1b47010758d2",
   "metadata": {},
   "source": [
    "### Prompt Improver\n",
    "\n",
    "We'll take the lazy approach and ask an LLM to recommend an improved set of tool descriptions that it \"thinks\" will improve tool selection.\n",
    "\n",
    "It'll be a basic map-reduce type operation:\n",
    "\n",
    "1. Map each failed case to an update\n",
    "2. Reduce the updates by the tool name\n",
    "3. Distill the updates per tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4c3ea78-3665-4b4e-a7df-7f2849d65cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import chain as as_runnable\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class FunctionUpdate(BaseModel):\n",
    "    name: str = Field(\n",
    "        description=\"The name of the tool whose description you'd like to update\"\n",
    "    )\n",
    "    updated_description: str = Field(\n",
    "        description=\"The updated description that would make it clear when and why to invoke this function.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ImproveToolDocumentation(BaseModel):\n",
    "    \"\"\"Called to update the docstrings and other information about a given tool\n",
    "    so that the user has an easier time selecting.\"\"\"\n",
    "\n",
    "    updates: List[FunctionUpdate] = Field(\n",
    "        description=\"The updates to make, one for each tool description you'd like to change\"\n",
    "    )\n",
    "\n",
    "\n",
    "improver_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an API documentation assistant tasked with meticulously improving the descriptions of our API docs.\"\n",
    "            \" Our AI assistant is trying to assist users by calling APIs, but it continues to invoke the wrong ones.\"\n",
    "            \" You must improve their documentation to remove ambiguity so that the assistant will no longer make any mistakes.\\n\\n\"\n",
    "            \"##Valid APIs\\nBelow are the existing APIs the assistant is choosing between:\\n```apis.json\\n{apis}\\n```\\n\\n\"\n",
    "            \"## Failure Case\\nBelow is a user query, expected API calls, and actual API calls.\"\n",
    "            \" Use this failure case to make motivated doc changes.\\n\\n```failure_case.json\\n{failure}\\n```\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Respond with the updated tool descriptions to clear up\"\n",
    "            \" whatever ambiguity caused the failure case above.\"\n",
    "            \" Feel free to mention what it is NOT appropriate for (if that's causing issues.), like 'don't use this for x'.\"\n",
    "            \" The updated description should reflect WHY the assistant got it wrong in the first place.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\").with_structured_output(ImproveToolDocumentation)\n",
    "\n",
    "improver_chain = improver_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2b34a01-6c59-474d-a4ee-f92f48a8d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "apis = json.dumps(tools, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d7ced71-4d08-4da2-86ce-2cdaf0b5fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_results.to_dataframe()\n",
    "# Filter out success cases\n",
    "df = df[df[\"feedback.tool_selection_precision\"] < 1]\n",
    "\n",
    "\n",
    "def format_inputs(series):\n",
    "    return {\n",
    "        \"apis\": apis,\n",
    "        \"failure\": json.dumps(\n",
    "            {\n",
    "                \"query\": series[\"inputs.query\"],\n",
    "                \"predicted\": [out[\"type\"] for out in series[\"output\"]],\n",
    "                \"expected\": series[\"reference.expected\"][0],\n",
    "            }\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "improver_inputs = df.apply(format_inputs, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf8d1c-8af4-4a16-afaf-189b50452554",
   "metadata": {},
   "source": [
    "#### Map errors -> updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e35eabf9-d051-473c-a46d-e45c7da0cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the basic \"Map\" step\n",
    "all_updates = improver_chain.batch(improver_inputs, return_exceptions=True)\n",
    "# Just in case one of the runs failed (OAI downtime, LLM error, etc.)\n",
    "all_updates = [u for u in all_updates if isinstance(u, ImproveToolDocumentation)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c0778-4b48-4599-b9af-7fb8f2dd4c41",
   "metadata": {},
   "source": [
    "#### Reduce updates per tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a125175-31fc-424d-8cfe-3cfaa3184281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "toolwise_updates = defaultdict(list)\n",
    "for updates in all_updates:\n",
    "    for tool_update in updates.updates:\n",
    "        toolwise_updates[tool_update.name].append(tool_update.updated_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcecf8bf-7bc2-4f6a-9aba-8cb6d814074b",
   "metadata": {},
   "source": [
    "#### Distill updates into a final description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f075478d-59f7-4521-aaaa-721350bc89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an API documentation assistant tasked with meticulously improving the descriptions of our API docs.\"\n",
    "            \" Our AI assistant is trying to help users by calling APIs, but it continues to invoke the wrong ones.\"\n",
    "            \" You are tasked with updating the {target_api} description.\\n\\n\"\n",
    "            \"## Current APIs\\n\"\n",
    "            \"Below is a list of the current APIs and descriptions.\\n\"\n",
    "            \"```apis.json\\n{apis}\\n```\\n\\n\"\n",
    "            \"## Candidates\\n\"\n",
    "            \" Here are some candidate desription improvements:\\n{candidates}\\n\"\n",
    "            \" Consider the above feedback in your updated description.\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Respond with the updated description for the {target_api} API.\"\n",
    "            \" It should distill and incorporate the candidate descriptions to\"\n",
    "            \" clear up whatever ambiguity is causing our AI assistant to fail.\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(apis=apis)\n",
    "\n",
    "distill_llm = ChatOpenAI(model=model).with_structured_output(FunctionUpdate)\n",
    "\n",
    "distill_chain = distill_prompt | distill_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7ed363e-4e1e-4716-80dc-de3b099600ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_inputs = [\n",
    "    {\n",
    "        \"target_api\": name,\n",
    "        \"candidates\": \"\\n\".join([\"- \" + c for c in candidates]),\n",
    "    }\n",
    "    for name, candidates in toolwise_updates.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70b69ca7-20dd-433a-a1ed-cb1089c19212",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_descriptions = distill_chain.batch(distill_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ddae40c-cf37-4295-a680-a41657e28ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TransportistasdeArgentina': 'Get a shipping quote for sending products within Argentina using OCA e-Pack. Provide destination and source postcodes, CUIT, operativa number, cost, volume, and weight details for accurate pricing.',\n",
       " 'TurkeyPostalCodes': 'Retrieve Turkish plate numbers (1 to 81) based on the city code. This API is specifically designed to provide details about Turkish plates and is not intended for tracking packages or obtaining postal codes for cities in Argentina.',\n",
       " 'CEPBrazil': 'Retrieve address details based on a Brazilian CEP number. This function is NOT intended for tracking package locations or statuses, tracking travel documents, or providing non-address related information. Use this API specifically for address lookup using CEP numbers in Brazil.',\n",
       " 'PridnestroviePost': 'Get track information by providing a track number for international shipments. Use this API specifically for tracking packages and shipments.',\n",
       " 'PackAndSend': 'If you have a Pack & Send Reference Number, use this API to track the delivery status and retrieve relevant information about the package. This API is specifically designed for tracking packages using the Pack & Send Reference Number, and it is not intended for providing postal code information for cities in a specific state.',\n",
       " 'TrackingMore_v2': 'List all supported carriers for package tracking. This API provides a comprehensive overview of available carriers for tracking packages. It is not intended for tracking specific package details, but rather for identifying carriers for package tracking services.',\n",
       " 'SQUAKE': 'This function does not have a defined purpose or parameters. Avoid using it as it does not serve any specific functionality. It is not suitable for tracking packages or retrieving package information.',\n",
       " 'AmexAustraliaFastwayAustraliaTracking': \"Track a package's shipping details specifically within Australia using a package tracking number. This API is designed for tracking packages shipped via the AmexAustraliaFastway service and is not suitable for tracking international shipments or non-package related inquiries.\",\n",
       " 'suivi-colis': 'Retrieve the current status (i.e., the latest status) of a package by providing the package ID. This function is suitable for tracking package statuses and obtaining real-time updates on delivery progress.',\n",
       " 'CreateContainerTracking': 'Retrieve data related to a container using the container ID provided. This API is suitable for tracking containers and retrieving their details.',\n",
       " 'Transitaires': 'Retrieve details about a specific transit company. This function is NOT designed for tracking packages or event planning.',\n",
       " 'KargomNerede': 'Retrieve a list of shipping companies.',\n",
       " 'GS1Parser': 'Parse machine- or human-readable GS1 barcode data.'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates_dict = {upd.name: upd.updated_description for upd in updated_descriptions}\n",
    "updates_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd251899-4e78-456e-a49a-4efb312560e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "new_tools = deepcopy(tools)\n",
    "for tool in new_tools:\n",
    "    name = tool[\"function\"][\"name\"]\n",
    "    if name in updates_dict:\n",
    "        updated = updates_dict[name]\n",
    "        tool[\"function\"][\"description\"] = updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba119ad-63ea-4381-9ea5-10ff5d02f7cc",
   "metadata": {},
   "source": [
    "## Re-Evaluate\n",
    "\n",
    "We will use the same LLM and prompt, only updating the tools descriptions (which are injected into the prompt on OpenAI's server)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b909156-4667-45b3-aa97-a00e222106b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=model).bind_tools(new_tools)\n",
    "\n",
    "updated_chain = assistant_prompt | llm | JsonOutputToolsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c7be884-e366-4878-9abf-44c83f402b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'ordinary-step-81' at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/462d8386-60c8-4cb3-84eb-6efeae3a1293/compare?selectedSessions=a4204d34-4d08-42fa-a84d-19b850ad920e\n",
      "\n",
      "View all tests for Dataset Tool Selection (Logistics) dev at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/462d8386-60c8-4cb3-84eb-6efeae3a1293\n",
      "[------------------------------------------------->] 99/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 033fd6d7-6c80-4ef2-ab26-e4116e4da24a with inputs {'query': \"I'm planning a family vacation to Brazil and I need to find a hotel in Rio de Janeiro. Can you provide me with a list of available hotels in Rio de Janeiro downtown? Additionally, I would like to know the current health status of the CEP Brazil API and if it's functioning properly.\"}\n",
      "Error Type: InternalServerError, Message: Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_35b74dde88208be45493f9827dc88674 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 100/100"
     ]
    }
   ],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "updated_test_results = client.run_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=updated_chain,\n",
    "    evaluation=eval_config,\n",
    "    project_metadata={\n",
    "        \"model\": model,\n",
    "        # Mark that this is a new tool descsription version\n",
    "        \"tool_variant\": 2,\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635ad65-4e6c-4404-8cbf-7c2d58183c03",
   "metadata": {},
   "source": [
    "The metrics look slightly better, though not beyond a standard margin of error. You can investigate the dataset and model output quality and refine either to make the process more useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6ee0c-f0a9-4b55-b55a-38b18ee7b418",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "We've been hill climbing on a single dataset, meaning that information about what we are evaluating on is seeping in to the model definition. Before concluding that variant B is better than A, you should benchmark both on a held-out set. Below are datasets that were sampled from the same ToolBench dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4c73b35-b393-4408-bc28-cc7f6f43b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_urls = {\n",
    "    # Dev is same as above\n",
    "    \"dev\": dev_dataset_url,\n",
    "    \"test\": \"https://smith.langchain.com/public/a5fd6197-36ed-4d06-993a-89929dded399/d\",\n",
    "    \"train\": \"https://smith.langchain.com/public/cf5a1de8-68f0-4170-9bcc-f263c1abb063/d\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb0deeb7-59ae-4bd7-8329-b6efef8fef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langsmith\n",
    "\n",
    "client = langsmith.Client()\n",
    "\n",
    "client.clone_public_dataset(dataset_urls[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4351689-b051-4ba1-87ed-af9757ce7ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'definite-coach-89' at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/ddc1bcf7-c3fb-4669-824d-eb2e23af93d0/compare?selectedSessions=2b7204c8-7f07-4c2c-b798-d9005a059ce0\n",
      "\n",
      "View all tests for Dataset Tool Selection (Logistics) test at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/ddc1bcf7-c3fb-4669-824d-eb2e23af93d0\n",
      "[------------------------------------------------->] 234/234View the evaluation results for project 'sparkling-doctor-64' at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/ddc1bcf7-c3fb-4669-824d-eb2e23af93d0/compare?selectedSessions=b9d4bd07-d96b-4da8-97df-279158ffafa1\n",
      "\n",
      "View all tests for Dataset Tool Selection (Logistics) test at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/ddc1bcf7-c3fb-4669-824d-eb2e23af93d0\n",
      "[------------------------------------------------> ] 231/234"
     ]
    }
   ],
   "source": [
    "test_dataset_name = \"Tool Selection (Logistics) test\"\n",
    "\n",
    "for target_chain in [chain, updated_chain]:\n",
    "    client.run_on_dataset(\n",
    "        dataset_name=test_dataset_name,\n",
    "        llm_or_chain_factory=chain,\n",
    "        evaluation=eval_config,\n",
    "        project_metadata={\n",
    "            \"model\": model,\n",
    "            # Mark that this is a new tool descsription version\n",
    "            \"tool_variant\": 2,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a523e7-f3b9-4a74-a713-0f2c7302d74a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
