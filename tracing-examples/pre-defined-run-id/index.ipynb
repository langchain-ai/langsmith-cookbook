{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Defined Run IDs\n",
    "\n",
    "Using LangChain, we offer the ability to pre-generate and define run IDs, before your code is invoked and the run ID is generated. With this functionality, you're able to access your run ID before initial generation, which can be useful for actions like sending feedback. The example below demonstrates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables.\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "import uuid\n",
    "\n",
    "lambda1 = RunnableLambda(lambda x: x + 1)\n",
    "lambda2 = RunnableLambda(lambda x: x * 2)\n",
    "\n",
    "pre_defined_run_id = uuid.uuid4()\n",
    "\n",
    "# pass in run_id to the RunnableConfig dict\n",
    "chain = (lambda1 | lambda2).with_config(run_id=pre_defined_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e53e7bc-03a7-4cba-822b-c5e75a9196cc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pre_defined_run_id)\n",
    "chain.invoke(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now, if we inspect the trace, and more specifically the trace's `run_id`, we cans see it matches the `pre_defined_run_id` we logged above!\n",
    "\n",
    "![LangSmith trace](./img/show_run_id.png)\n",
    "\n",
    "Now, let's see how we can implement this for sending feedback on a run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Anthropic in this example, but you can swap it with any LLM you'd like.\n",
    "\n",
    "First, set the required environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-ant-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-anthropic langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1aea0dde-c893-487a-bc02-17fe5d1e0b40\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model_name=\"claude-3-haiku-20240307\")\n",
    "\n",
    "llm_feedback_uuid = uuid.uuid4()\n",
    "\n",
    "res = llm.invoke(\n",
    "    \"Did I implement this correctly?\", config={\"run_id\": llm_feedback_uuid}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('18011750-e5c7-46b7-bc56-90c352fb87a0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_feedback_uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without reading the response of the LLM, we can send feedback on the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedback(id=UUID('d9ed2d40-26aa-405c-9ee2-6b4c19486d8c'), created_at=datetime.datetime(2024, 4, 5, 19, 22, 7, 670095, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 4, 5, 19, 22, 7, 670098, tzinfo=datetime.timezone.utc), run_id=UUID('31336494-6a30-415a-ba26-8a343fdb333a'), key='user_feedback', score=1, value=None, comment=None, correction=None, feedback_source=FeedbackSourceBase(type='api', metadata={}), session_id=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "client.create_feedback(llm_feedback_uuid, \"user_feedback\", score=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, if we inspect the LangSmith run we'll see the feedback is linked to the run we just executed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be helpful for pre-signed feedback URLs. You would want to use these when you can't expose API keys or other secrets to the client, e.g. in a web application. Using a pre-determined `run_id` LangSmith has an endpoint `create_presigned_feedback_token` which will create a URL for sending feedback, without the use of secrets required.\n",
    "\n",
    "Let's see how we can implement this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=UUID('9491a59d-e345-4713-813a-95dfbc39f3b5') url='https://api.smith.langchain.com/feedback/tokens/9491a59d-e345-4713-813a-95dfbc39f3b5' expires_at=datetime.datetime(2024, 4, 5, 22, 28, 8, 976569, tzinfo=datetime.timezone.utc)\n"
     ]
    }
   ],
   "source": [
    "# Define your UUID for the `run_id`\n",
    "\n",
    "pre_signed_url_id = uuid.uuid4()\n",
    "\n",
    "pre_signed_url = client.create_presigned_feedback_token(\n",
    "    pre_signed_url_id, \"user_feedback\"\n",
    ")\n",
    "\n",
    "print(pre_signed_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that even though we haven't created a run yet, we're still able to generate the feedback URL.\n",
    "\n",
    "Now, let's invoke our LLM so the run with that ID is created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.invoke(\n",
    "    \"Have you heard the news?! LangSmith offers pre-signed feedback URLs now!!\",\n",
    "    config={\"run_id\": pre_signed_url},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, once our run is created, we can use the feedback URL to send feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback submitted successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url_with_score = f\"{pre_signed_url.url}?score=1\"\n",
    "\n",
    "response = requests.get(url_with_score)\n",
    "\n",
    "if response.status_code >= 200 and response.status_code < 300:\n",
    "    print(\"Feedback submitted successfully!\")\n",
    "else:\n",
    "    print(\"Feedback submission failed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
