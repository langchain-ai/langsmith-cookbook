{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b8c61a-94eb-4f13-83ec-0f6db5a4822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Env\n",
    "\n",
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true' # enables tracing \n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"xxx\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG-feedback-and-few-shot\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839e984-5c01-49da-ad10-80ae00bace2a",
   "metadata": {},
   "source": [
    "### Creating a RAG bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd922eb-0407-4de4-81d7-0e3e789c0b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "### Index\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1839bd-f291-43ed-8033-0aaa707f6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RAG bot\n",
    "\n",
    "import openai\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "class RagBot:\n",
    "\n",
    "    def __init__(self, retriever, model: str = \"gpt-4o\"):\n",
    "        self._retriever = retriever\n",
    "        # Wrapping the client instruments the LLM\n",
    "        self._client = wrap_openai(openai.Client())\n",
    "        self._model = model\n",
    "\n",
    "    @traceable()\n",
    "    def retrieve_docs(self, question):\n",
    "        return self._retriever.invoke(question)\n",
    "\n",
    "    @traceable()\n",
    "    def invoke_llm(self, question, docs):\n",
    "        response = self._client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful AI assistant for question answering.\"\n",
    "                    \" Use the following docs to answer the user question.\\n\\n\"\n",
    "                    f\"## Docs\\n\\n{docs}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Evaluators will expect \"answer\" and \"contexts\"\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"contexts\": [str(doc.page_content) for doc in docs],\n",
    "        }\n",
    "\n",
    "    @traceable()\n",
    "    def get_answer(self, question: str):\n",
    "        docs = self.retrieve_docs(question)\n",
    "        return self.invoke_llm(question, docs)\n",
    "\n",
    "rag_bot = RagBot(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc965f0-d1ce-414b-afd5-1662b7631a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The ReAct (Reasoning and Acting) agent integrates reasoning and acting capabilities within Large Language Models (LLMs) by extending the action space '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_bot.get_answer(\"How does ReAct agent work?\")\n",
    "response[\"answer\"][:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7b382-5e9f-43b3-8040-f8b9eef41618",
   "metadata": {},
   "source": [
    "### Setting an online evaluator\n",
    "\n",
    "Now, we see traces logged to our project.\n",
    "\n",
    "We can add an evaluator to our project.\n",
    "\n",
    "Let's do document grading, which is a very useful check! \n",
    "\n",
    "https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_crag.ipynb\n",
    "\n",
    "Grade documents:\n",
    "\n",
    "https://docs.smith.langchain.com/tutorials/Developers/rag#evaluator\n",
    " \n",
    "`Recall:`\n",
    "```\n",
    "You are a teacher grading a quiz. \n",
    "\n",
    "You will be given: \n",
    "\n",
    "1/ a QUESTION \n",
    "\n",
    "2/ a set of 4 comma separated FACTS provided by the student\n",
    "\n",
    "You are grading RELEVANCE RECALL. \n",
    "\n",
    "A score of 1 means that ANY of the FACTS are relevant to the QUESTION. \n",
    "\n",
    "A score of 0 means that NONE of the FACTS are relevant to the QUESTION. \n",
    "\n",
    "1 is the highest (best) score. 0 is the lowest score you can give. \n",
    "\n",
    "Explain your reasoning in a step-by-step manner. Ensure your reasoning and conclusion are correct. Avoid simply stating the correct answer at the outset.\n",
    "\n",
    "Here are some examples to guide your grading:\n",
    "\n",
    "{{Few-shot examples}}\n",
    "```\n",
    "\n",
    "And precision:\n",
    "\n",
    "```\n",
    "You are a teacher grading a quiz.\n",
    "\n",
    "You will be given: \n",
    "\n",
    "1/ a QUESTION\n",
    "\n",
    "2/ a set of comma separated FACTS provided by the student \n",
    "\n",
    "You are grading RELEVANCE PRECISION. \n",
    "\n",
    "Consider each of the comma separated facts.\n",
    "\n",
    "A score of 1 means that ALL of the FACTS are relevant to the QUESTION. \n",
    "\n",
    "A score of 0 means that ANY of the FACTS are not relevant to the QUESTION.\n",
    "\n",
    "1 is the highest (best) score.\n",
    "\n",
    "0 is the lowest score you can give.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner. \n",
    "\n",
    "Ensure your reasoning and conclusion are correct. \n",
    "\n",
    "Avoid simply stating the correct answer at the outset.\n",
    "\n",
    "Here are some examples to guide your grading:\n",
    "\n",
    "{{Few-shot examples}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94cfef3b-f0a3-4c8c-95d0-29908f21d8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Both ReAct and Reflexion are approaches designed to enhance the capabilities of autonomous agents, particularly in reasoning and decision-making tasks, but they differ in their mechanisms and focuses for self-reflection:\\n\\n### ReAct (Reason + Act)\\n1. **Integration of Reasoning and Acting:** ReAct combines reasoning and acting within a large language model (LLM) by extending the action space to include both task-specific actions and natural language.\\n2. **Prompting Structure:** It follows a specific structure for the LLM to think and act, typically using a repeated sequence of \"Thought: … Action: … Observation: …\".\\n3. **Self-Reflection by Design:** Although ReAct suggests including reasoning steps, it doesn\\'t explicitly describe a structured framework for self-correcting past actions in the way Reflexion does.\\n\\n### Reflexion\\n1. **Dynamic Memory and Self-Reflection:** Reflexion equips agents with dynamic memory and self-reflection capabilities to iteratively improve their reasoning skills.\\n2. **Heuristic and Reset Mechanism:** After each action, Reflexion agents compute a heuristic to evaluate the trajectory. If the trajectory is deemed inefficient or hallucinatory, the agent may reset the environment, guided by the self-reflection results.\\n3. **Use of Failure Examples:** Reflexion creates self-reflection by presenting the LLM with examples of failed trajectories and ideal reflections to guide future decisions, thus using past mistakes actively to inform future actions.\\n4. **Contextual Reflection Usage:** Reflections are stored in the agent’s working memory and used as context for querying the LLM, typically up to three reflections concurrently.\\n\\n### Summary of Differences\\n- **Structured Self-Reflection:** Reflexion has a more explicit and structured approach to self-reflection, actively using past failure examples to guide future actions, while ReAct incorporates reasoning steps as part of its behavior but without such a detailed reflection mechanism.\\n- **Heuristics and Memory:** Reflexion agents use heuristics to determine when to reset and learn from mistakes, storing reflections in memory. ReAct does not detail such mechanisms, focusing instead on real-time reasoning and actions.\\n- **Prompting Mechanism:** ReAct uses a structured prompting format within the reasoning and acting workflow, whereas Reflexion utilizes examples of failed actions and reflections to iteratively improve the agent’s performance.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_bot.get_answer(\"What is the difference between ReAct and Reflexion approaches for self-reflection?\")\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55bff6ce-bcd8-4cdd-b5c6-92723281e9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The types of memory in LLM-powered autonomous agents, as described by Lilian Weng, are derived from the concepts of human memory. Here are the types highlighted:\\n\\n1. **Sensory Memory**: The earliest stage of memory, which retains impressions of sensory information (visual, auditory, etc.) after the original stimuli have ended. Sensory memory typically lasts for only a few seconds and includes subcategories such as:\\n   - **Iconic Memory**: Visual sensory memory.\\n   - **Echoic Memory**: Auditory sensory memory.\\n   - **Haptic Memory**: Tactile sensory memory.\\n\\nThe idea is to draw a parallel between human memory processes and the memory components used in LLM-powered systems, though the practical implementations may differ.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_bot.get_answer(\"What are the types of LLM memory?\")\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1000d77a-cb7b-4684-97c8-60ebeb2460f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In Generative Agents simulation, the memory and retrieval model are key components that enable the agent to behave in a human-like manner by utilizing past experiences. Here's a detailed breakdown:\\n\\n### Memory:\\n1. **Memory Stream**: This is a long-term memory module that acts as an external database, recording a comprehensive list of the agent's experiences in natural language. It allows the agent to have an extensive history to reference when making decisions.\\n\\n2. **Types of Memory**:\\n   - **Short-term Memory**: Utilized for in-context learning, enabling the model to handle immediate tasks and interactions.\\n   - **Long-term Memory**: Retains and recalls information over extended periods. This is achieved by leveraging an external vector store for fast retrieval, providing the agent with a considerable amount of stored data.\\n\\n### Retrieval Model:\\n1. **Context Surfacing**: The retrieval model surfaces relevant context to inform the agent's behavior. It considers three primary criteria:\\n   - **Recency**: Recent events are scored higher.\\n   - **Importance**: Distinguishes mundane memories from core memories.\\n   - **Relevance**: Determines how related a memory is to the current situation or query.\\n\\n2. **Reflection Mechanism**: This synthesizes memories into higher-level inferences over time and guides the agent’s future behavior. \\n   - It generates high-level summaries of past events.\\n   - The process involves prompting the language model with the most recent observations to generate salient high-level questions, which are then answered by the model.\\n\\n### Planning & Reacting:\\n- This element translates the reflections and environment information into actionable plans. The agent uses the synthesized insights from past experiences (via reflection and memory retrieval) to determine its next actions.\\n\\nThese memory and retrieval components work together to provide the generative agents with a rich, context-aware simulation of human behavior, enabling them to interact in a complex and realistic manner.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_bot.get_answer(\"What is the Memory and Retrieval model in Generative Agents simulation?\")\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb69149-71f4-47ac-adbd-91b6a3cf205e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85738f-f1bd-4b9a-bc95-cd46e099dae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f9471-6c9a-439b-b533-c891564a3c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770bab62-2c3c-4d28-8adc-4c9495feea2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71cf5f1-f486-4fbd-a90d-54ec7f14305f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdef171-144f-4ff7-9e8b-5fd1e7a0c38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd666442-148f-4a84-997f-f2001c8eacf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd5349-e179-40c0-9d03-44cb31041c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc26fa8-65c2-4de6-9c39-21b53ace6ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
